{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def delete_punctuation(x):\n",
    "    return ''.join([a for a in x if a not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Shengy's code:\n",
    "# http://stackoverflow.com/questions/18840640/python-2-7-find-and-replace-from-text-file-using-dictionary-to-new-text-file\n",
    "\n",
    "def replace_all(text, mydict):\n",
    "    for gb, us in mydict.items():\n",
    "        text = text.replace(us, gb)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {'behaviour': 'behavior',\n",
    "         'favourable': 'favorable',\n",
    "         'labour': 'labor',\n",
    "         'organisation': 'organization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on DataCamp article:\n",
    "# http://datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# from nltk.stem import PorterStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# porter = PorterStemmer()\n",
    "\n",
    "def stemText(text):\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_text = list()\n",
    "    for word in token_words:\n",
    "        stem_text.append(lemmatizer.lemmatize(word))\n",
    "        # stem_text.append(porter.stem(word))\n",
    "        stem_text.append(' ')\n",
    "    return ''.join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capital = os.listdir(os.getcwd() + '/Classes')\n",
    "# for i in range(len(capital)):\n",
    "    # capital[i] = capital[i].replace('.txt', '')\n",
    "capital = ['structural', 'human', 'relational', 'social', 'natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRUCTURAL\n",
      "Accreditation\n",
      "Certificate\n",
      "Corporate culture\n",
      "Customer support function\n",
      "Distribution network\n",
      "Financial dealings\n",
      "Innovation\n",
      "Intellectual property\n",
      "Knowledge-based infrastructure\n",
      "Management philosophy\n",
      "Networking\n",
      "Organisation flexibility\n",
      "Organisation learning\n",
      "Organisation structure\n",
      "Overall capability\n",
      "Overall infrastructure\n",
      "Process\n",
      "Quality management and improvement\n",
      "Research and development\n",
      "Technology\n",
      "\n",
      "HUMAN\n",
      "Employee age\n",
      "Employee attitude\n",
      "Employee behaviour\n",
      "Employee capability\n",
      "Employee commitment\n",
      "Employee development\n",
      "Employee diversity\n",
      "Employee education\n",
      "Employee equality\n",
      "Employee flexibility\n",
      "Employee involvement with community\n",
      "Employee motivation\n",
      "Employee productivity\n",
      "Employee relationship\n",
      "Employee teamwork\n",
      "Employee training\n",
      "Employee work-related competence\n",
      "Employee work-related knowledge\n",
      "Entrepreneurial spirit\n",
      "Know-how\n",
      "Number of employees\n",
      "Skill\n",
      "Vocational qualification\n",
      "\n",
      "RELATIONAL\n",
      "Acquaintance with community\n",
      "Acquaintance with government\n",
      "Acquaintance with suppliers\n",
      "Basic marketing capability\n",
      "Brand\n",
      "Business collaboration\n",
      "Client profile\n",
      "Commercial power\n",
      "Competitive intelligence\n",
      "Competitor\n",
      "Connectivity\n",
      "Corporate image and reputation\n",
      "Customer knowledge\n",
      "Customer loyalty\n",
      "Customer name\n",
      "Customer relationship\n",
      "Customer reputation\n",
      "Customer satisfaction\n",
      "Diffusion\n",
      "Distribution\n",
      "Distribution channel\n",
      "Environmental activity\n",
      "External contract\n",
      "Favourable contract\n",
      "Financial contract\n",
      "Financial relations\n",
      "Franchise agreement\n",
      "Government relationship\n",
      "Image\n",
      "Intensity\n",
      "Joint venture\n",
      "Licensing agreement\n",
      "Link with suppliers\n",
      "Market intensity\n",
      "Market share\n",
      "Mergers and acquisitions\n",
      "New strategic customer\n",
      "Private-public partnership\n",
      "Reputation\n",
      "Research collaboration\n",
      "Stakeholder\n",
      "Strategic alliance\n",
      "Subsidiaries and associates\n",
      "\n",
      "SOCIAL\n",
      "Anti-competitive behaviour\n",
      "Anti-monopoly practice\n",
      "Anti-trust practice\n",
      "Child\n",
      "Collective bargaining\n",
      "Community development\n",
      "Commuting incident\n",
      "Conflict of interests\n",
      "Corruption\n",
      "Discrimination\n",
      "Diversity\n",
      "Exposure\n",
      "Forced labour\n",
      "Freedom of association\n",
      "Full coverage\n",
      "Health and safety\n",
      "Health promotion\n",
      "Human rights\n",
      "Indigenous people\n",
      "Local communities\n",
      "Local minimum wage\n",
      "Local suppliers\n",
      "Occupational health services\n",
      "Parental leave\n",
      "Political contribution\n",
      "Substantiated complaint\n",
      "Under-represented social group\n",
      "Vulnerable group\n",
      "Work-related hazard\n",
      "Work-related ill health\n",
      "Work-related incident\n",
      "Work-related injury\n",
      "Worker representative\n",
      "\n",
      "NATURAL\n",
      "Air emission\n",
      "Biodiversity\n",
      "Carbon dioxide\n",
      "Catchment\n",
      "Conservation initiative\n",
      "Efficiency initiative\n",
      "Effluent\n",
      "Energy reduction\n",
      "Environmental law\n",
      "Environmental protection\n",
      "Environmental regulation\n",
      "Freshwater\n",
      "Global warming potential\n",
      "Greenhouse gas\n",
      "Groundwater\n",
      "Ozone-depleting substance\n",
      "Produced water\n",
      "Protected area\n",
      "Reclaimed\n",
      "Recycled material\n",
      "Renewable energy source\n",
      "Renewable material\n",
      "Restored area\n",
      "Runoff\n",
      "Seawater\n",
      "Spill\n",
      "Surface water\n",
      "Third-party water\n",
      "Waste disposal method\n",
      "Water consumption\n",
      "Water discharge\n",
      "Water stewardship\n",
      "Water storage\n",
      "Water stress\n",
      "Water withdrawal\n"
     ]
    }
   ],
   "source": [
    "for item in capital:\n",
    "    file = open('Classes/' + item + '.txt')\n",
    "    print(item.upper())\n",
    "    for line in file.readlines():\n",
    "        print(line.replace('\\n', ''))\n",
    "    if not item == capital[len(capital) - 1]:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keywords = list()\n",
    "for item in capital:\n",
    "    file = open('Classes/' + item + '.txt')\n",
    "    text = delete_punctuation(file.read().replace('\\n', ' zzz ').replace('  ', ' ').replace('  ', ' ').lower())\n",
    "    text = stemText(replace_all(text, mydict))\n",
    "    newlist = text.split('zzz')\n",
    "    for i in range(len(newlist)):\n",
    "        newlist[i] = newlist[i].strip()\n",
    "    keywords.append([item, newlist])\n",
    "# keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structural: 20\n",
      "human: 23\n",
      "relational: 43\n",
      "social: 33\n",
      "natural: 35\n"
     ]
    }
   ],
   "source": [
    "for item in keywords:\n",
    "    print(item[0] + ': ' + str(len(item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(os.listdir(os.getcwd() + '/Files'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list()\n",
    "for filename in files:\n",
    "    file = open('Files/' + filename)\n",
    "    text = delete_punctuation(file.read().replace('\\n', ' ').replace('  ', ' ').replace('  ', ' ').lower())\n",
    "    text = stemText(replace_all(text, mydict))\n",
    "    df.append([])\n",
    "    for item in keywords:\n",
    "        count = 0\n",
    "        for word in item[1]:\n",
    "            if not text.find(word) == -1:\n",
    "                count += 1\n",
    "        df[len(df) - 1].append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(df)\n",
    "overall = df.sum(axis=1)\n",
    "\n",
    "files = pd.DataFrame(files)\n",
    "df = pd.DataFrame(df)\n",
    "overall = pd.DataFrame(overall)\n",
    "\n",
    "df = pd.concat([files, df, overall], axis=1, ignore_index=True)\n",
    "df.columns = ['name'] + capital + ['overall']\n",
    "df.index = df['name']\n",
    "del df['name']\n",
    "\n",
    "dff = pd.read_csv('performance.csv', sep=';')\n",
    "dff.index = df.index\n",
    "df = pd.concat([df, dff], axis=1, ignore_index=True)\n",
    "df.columns = capital + ['overall'] + list(dff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structural</th>\n",
       "      <th>human</th>\n",
       "      <th>relational</th>\n",
       "      <th>social</th>\n",
       "      <th>natural</th>\n",
       "      <th>overall</th>\n",
       "      <th>current_assets</th>\n",
       "      <th>non-current_assets</th>\n",
       "      <th>current_liab</th>\n",
       "      <th>non-current_liab</th>\n",
       "      <th>equity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue_prev</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>EBIT_prev</th>\n",
       "      <th>net_operat_CF</th>\n",
       "      <th>units_EUR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adidas_IR_2014.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>7497.0</td>\n",
       "      <td>5846.0</td>\n",
       "      <td>5364.0</td>\n",
       "      <td>2332.0</td>\n",
       "      <td>5648.0</td>\n",
       "      <td>16915.0</td>\n",
       "      <td>14534.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adidas_IR_2015.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>8886.0</td>\n",
       "      <td>6290.0</td>\n",
       "      <td>6765.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>6455.0</td>\n",
       "      <td>19291.0</td>\n",
       "      <td>16915.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adidas_IR_2016.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>8645.0</td>\n",
       "      <td>5877.0</td>\n",
       "      <td>6291.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>6435.0</td>\n",
       "      <td>21218.0</td>\n",
       "      <td>18483.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi_IR_2014.txt</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>30800.0</td>\n",
       "      <td>25963.0</td>\n",
       "      <td>21554.0</td>\n",
       "      <td>13431.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>58420.0</td>\n",
       "      <td>53787.0</td>\n",
       "      <td>4836.0</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>7203.0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi_IR_2015.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>32490.0</td>\n",
       "      <td>28599.0</td>\n",
       "      <td>20789.0</td>\n",
       "      <td>14980.0</td>\n",
       "      <td>25321.0</td>\n",
       "      <td>59317.0</td>\n",
       "      <td>58240.0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>4836.0</td>\n",
       "      <td>7517.0</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    structural  human  relational  social  natural  overall  \\\n",
       "name                                                                          \n",
       "Adidas_IR_2014.txt           5      2           6      10        3       26   \n",
       "Adidas_IR_2015.txt           5      2           6      11        7       31   \n",
       "Adidas_IR_2016.txt           3      3           4       8       10       28   \n",
       "Audi_IR_2014.txt             8      3          10      17       19       57   \n",
       "Audi_IR_2015.txt             3      1           3       3        7       17   \n",
       "\n",
       "                    current_assets  non-current_assets  current_liab  \\\n",
       "name                                                                   \n",
       "Adidas_IR_2014.txt          7497.0              5846.0        5364.0   \n",
       "Adidas_IR_2015.txt          8886.0              6290.0        6765.0   \n",
       "Adidas_IR_2016.txt          8645.0              5877.0        6291.0   \n",
       "Audi_IR_2014.txt           30800.0             25963.0       21554.0   \n",
       "Audi_IR_2015.txt           32490.0             28599.0       20789.0   \n",
       "\n",
       "                    non-current_liab   equity  revenue  revenue_prev    EBIT  \\\n",
       "name                                                                           \n",
       "Adidas_IR_2014.txt            2332.0   5648.0  16915.0       14534.0  1059.0   \n",
       "Adidas_IR_2015.txt            1957.0   6455.0  19291.0       16915.0  1491.0   \n",
       "Adidas_IR_2016.txt            1796.0   6435.0  21218.0       18483.0  2070.0   \n",
       "Audi_IR_2014.txt             13431.0  21779.0  58420.0       53787.0  4836.0   \n",
       "Audi_IR_2015.txt             14980.0  25321.0  59317.0       58240.0  3052.0   \n",
       "\n",
       "                    EBIT_prev  net_operat_CF  units_EUR  \n",
       "name                                                     \n",
       "Adidas_IR_2014.txt      883.0         1090.0    1000000  \n",
       "Adidas_IR_2015.txt     1059.0         1348.0    1000000  \n",
       "Adidas_IR_2016.txt     1582.0         1648.0    1000000  \n",
       "Audi_IR_2014.txt       5150.0         7203.0    1000000  \n",
       "Audi_IR_2015.txt       4836.0         7517.0    1000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('export.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
