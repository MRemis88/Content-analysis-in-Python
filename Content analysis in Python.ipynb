{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def delete_punctuation(x):\n",
    "    return ''.join([a for a in x if a not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Shengy's code:\n",
    "# http://stackoverflow.com/questions/18840640/python-2-7-find-and-replace-from-text-file-using-dictionary-to-new-text-file\n",
    "\n",
    "def replace_all(text, mydict):\n",
    "    for gb, us in mydict.items():\n",
    "        text = text.replace(us, gb)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {'behaviour': 'behavior',\n",
    "         'favourable': 'favorable',\n",
    "         'labour': 'labor',\n",
    "         'organisation': 'organization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on DataCamp article:\n",
    "# http://datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# from nltk.stem import PorterStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# porter = PorterStemmer()\n",
    "\n",
    "def stemText(text):\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_text = list()\n",
    "    for word in token_words:\n",
    "        stem_text.append(lemmatizer.lemmatize(word))\n",
    "        # stem_text.append(porter.stem(word))\n",
    "        stem_text.append(' ')\n",
    "    return ''.join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capital = os.listdir(os.getcwd() + '/Classes')\n",
    "# for i in range(len(capital)):\n",
    "    # capital[i] = capital[i].replace('.txt', '')\n",
    "capital = ['structural', 'human', 'relational', 'social', 'natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRUCTURAL\n",
      "Accreditation\n",
      "Certificate\n",
      "Corporate culture\n",
      "Customer support function\n",
      "Distribution network\n",
      "Financial dealings\n",
      "Innovation\n",
      "Intellectual property\n",
      "Knowledge-based infrastructure\n",
      "Management philosophy\n",
      "Networking\n",
      "Organisation flexibility\n",
      "Organisation learning\n",
      "Organisation structure\n",
      "Overall capability\n",
      "Overall infrastructure\n",
      "Process\n",
      "Quality management and improvement\n",
      "Research and development\n",
      "Technology\n",
      "\n",
      "HUMAN\n",
      "Employee age\n",
      "Employee attitude\n",
      "Employee behaviour\n",
      "Employee capability\n",
      "Employee commitment\n",
      "Employee development\n",
      "Employee diversity\n",
      "Employee education\n",
      "Employee equality\n",
      "Employee flexibility\n",
      "Employee involvement with community\n",
      "Employee motivation\n",
      "Employee productivity\n",
      "Employee relationship\n",
      "Employee teamwork\n",
      "Employee training\n",
      "Employee work-related competence\n",
      "Employee work-related knowledge\n",
      "Entrepreneurial spirit\n",
      "Know-how\n",
      "Number of employees\n",
      "Skill\n",
      "Vocational qualification\n",
      "\n",
      "RELATIONAL\n",
      "Acquaintance with community\n",
      "Acquaintance with government\n",
      "Acquaintance with suppliers\n",
      "Basic marketing capability\n",
      "Brand\n",
      "Business collaboration\n",
      "Client profile\n",
      "Commercial power\n",
      "Competitive intelligence\n",
      "Competitor\n",
      "Connectivity\n",
      "Corporate image and reputation\n",
      "Customer knowledge\n",
      "Customer loyalty\n",
      "Customer name\n",
      "Customer relationship\n",
      "Customer reputation\n",
      "Customer satisfaction\n",
      "Diffusion\n",
      "Distribution\n",
      "Distribution channel\n",
      "Environmental activity\n",
      "External contract\n",
      "Favourable contract\n",
      "Financial contract\n",
      "Financial relations\n",
      "Franchise agreement\n",
      "Government relationship\n",
      "Image\n",
      "Intensity\n",
      "Joint venture\n",
      "Licensing agreement\n",
      "Link with suppliers\n",
      "Market intensity\n",
      "Market share\n",
      "Mergers and acquisitions\n",
      "New strategic customer\n",
      "Private-public partnership\n",
      "Reputation\n",
      "Research collaboration\n",
      "Stakeholder\n",
      "Strategic alliance\n",
      "Subsidiaries and associates\n",
      "\n",
      "SOCIAL\n",
      "Anti-competitive behaviour\n",
      "Anti-monopoly practice\n",
      "Anti-trust practice\n",
      "Child\n",
      "Collective bargaining\n",
      "Community development\n",
      "Commuting incident\n",
      "Conflict of interests\n",
      "Corruption\n",
      "Discrimination\n",
      "Diversity\n",
      "Exposure\n",
      "Forced labour\n",
      "Freedom of association\n",
      "Full coverage\n",
      "Health and safety\n",
      "Health promotion\n",
      "Human rights\n",
      "Indigenous people\n",
      "Local communities\n",
      "Local minimum wage\n",
      "Local suppliers\n",
      "Occupational health services\n",
      "Parental leave\n",
      "Political contribution\n",
      "Substantiated complaint\n",
      "Under-represented social group\n",
      "Vulnerable group\n",
      "Work-related hazard\n",
      "Work-related ill health\n",
      "Work-related incident\n",
      "Work-related injury\n",
      "Worker representative\n",
      "\n",
      "NATURAL\n",
      "Air emission\n",
      "Biodiversity\n",
      "Carbon dioxide\n",
      "Catchment\n",
      "Conservation initiative\n",
      "Efficiency initiative\n",
      "Effluent\n",
      "Energy reduction\n",
      "Environmental law\n",
      "Environmental protection\n",
      "Environmental regulation\n",
      "Freshwater\n",
      "Global warming potential\n",
      "Greenhouse gas\n",
      "Groundwater\n",
      "Ozone-depleting substance\n",
      "Produced water\n",
      "Protected area\n",
      "Reclaimed\n",
      "Recycled material\n",
      "Renewable energy source\n",
      "Renewable material\n",
      "Restored area\n",
      "Runoff\n",
      "Seawater\n",
      "Spill\n",
      "Surface water\n",
      "Third-party water\n",
      "Waste disposal method\n",
      "Water consumption\n",
      "Water discharge\n",
      "Water stewardship\n",
      "Water storage\n",
      "Water stress\n",
      "Water withdrawal\n"
     ]
    }
   ],
   "source": [
    "for item in capital:\n",
    "    file = open('Classes/' + item + '.txt')\n",
    "    print(item.upper())\n",
    "    for line in file.readlines():\n",
    "        print(line.replace('\\n', ''))\n",
    "    if not item == capital[len(capital) - 1]:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keywords = list()\n",
    "for item in capital:\n",
    "    file = open('Classes/' + item + '.txt')\n",
    "    text = delete_punctuation(file.read().replace('\\n', ' zzz ').replace('  ', ' ').replace('  ', ' ').lower())\n",
    "    text = stemText(replace_all(text, mydict))\n",
    "    newlist = text.split('zzz')\n",
    "    for i in range(len(newlist)):\n",
    "        newlist[i] = newlist[i].strip()\n",
    "    keywords.append([item, newlist])\n",
    "# keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structural: 20\n",
      "human: 23\n",
      "relational: 43\n",
      "social: 33\n",
      "natural: 35\n"
     ]
    }
   ],
   "source": [
    "for item in keywords:\n",
    "    print(item[0] + ': ' + str(len(item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(os.listdir(os.getcwd() + '/Files'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list()\n",
    "for filename in files:\n",
    "    file = open('Files/' + filename)\n",
    "    text = delete_punctuation(file.read().replace('\\n', ' ').replace('  ', ' ').replace('  ', ' ').lower())\n",
    "    text = stemText(replace_all(text, mydict))\n",
    "    df.append([])\n",
    "    for item in keywords:\n",
    "        count = 0\n",
    "        for word in item[1]:\n",
    "            if not text.find(word) == -1:\n",
    "                count += 1\n",
    "        df[len(df) - 1].append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(df)\n",
    "overall = df.sum(axis=1)\n",
    "\n",
    "files = pd.DataFrame(files)\n",
    "df = pd.DataFrame(df)\n",
    "overall = pd.DataFrame(overall)\n",
    "\n",
    "df = pd.concat([files, df, overall], axis=1, ignore_index=True)\n",
    "df.columns = ['name'] + capital + ['overall']\n",
    "df.index = df['name']\n",
    "del df['name']\n",
    "\n",
    "dff = pd.read_csv('performance.csv', sep=';')\n",
    "dff.index = df.index\n",
    "df = pd.concat([df, dff], axis=1, ignore_index=True)\n",
    "df.columns = capital + ['overall'] + list(dff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structural</th>\n",
       "      <th>human</th>\n",
       "      <th>relational</th>\n",
       "      <th>social</th>\n",
       "      <th>natural</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>margin</th>\n",
       "      <td>0.203380</td>\n",
       "      <td>0.334884</td>\n",
       "      <td>0.222090</td>\n",
       "      <td>0.322808</td>\n",
       "      <td>0.143127</td>\n",
       "      <td>0.301360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROCE</th>\n",
       "      <td>0.211031</td>\n",
       "      <td>0.263791</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.117160</td>\n",
       "      <td>0.142513</td>\n",
       "      <td>0.200308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>0.028910</td>\n",
       "      <td>0.125363</td>\n",
       "      <td>-0.031022</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.110730</td>\n",
       "      <td>0.074098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOCF</th>\n",
       "      <td>0.127620</td>\n",
       "      <td>0.342203</td>\n",
       "      <td>0.100029</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.156146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearing</th>\n",
       "      <td>0.109944</td>\n",
       "      <td>0.127340</td>\n",
       "      <td>0.169542</td>\n",
       "      <td>0.233692</td>\n",
       "      <td>0.257048</td>\n",
       "      <td>0.266781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         structural     human  relational    social   natural   overall\n",
       "margin     0.203380  0.334884    0.222090  0.322808  0.143127  0.301360\n",
       "ROCE       0.211031  0.263791    0.112000  0.117160  0.142513  0.200308\n",
       "revenue    0.028910  0.125363   -0.031022  0.024722  0.110730  0.074098\n",
       "NOCF       0.127620  0.342203    0.100029  0.074227  0.079070  0.156146\n",
       "gearing    0.109944  0.127340    0.169542  0.233692  0.257048  0.266781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[capital + ['overall']].tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
